{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_model (generic function with 2 methods)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"Brute_force/brute_force.jl\")\n",
    "include(\"NeuralNetwork/Separability_check.jl\")\n",
    "include(\"NeuralNetwork/symmetry_check.jl\")\n",
    "include(\"NeuralNetwork/train.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a equation for 500 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs  :1  Validation loss :4766.0923  Training loss :5868.368\n",
      "Epochs  :2  Validation loss :4748.947  Training loss :5838.945\n",
      "Epochs  :3  Validation loss :4737.6753  Training loss :5825.5693\n",
      "Epochs  :4  Validation loss :4728.4155  Training loss :5816.387\n",
      "Epochs  :5  Validation loss :4720.0405  Training loss :5808.6025\n",
      "Epochs  :6  Validation loss :4712.2607  Training loss :5801.469\n",
      "Epochs  :7  Validation loss :4704.913  Training loss :5794.762\n",
      "Epochs  :8  Validation loss :4697.9526  Training loss :5788.3643\n",
      "Epochs  :9  Validation loss :4691.3374  Training loss :5782.248\n",
      "Epochs  :10  Validation loss :4684.9004  Training loss :5776.4\n",
      "Epochs  :11  Validation loss :4678.5425  Training loss :5770.6636\n",
      "Epochs  :12  Validation loss :4672.282  Training loss :5765.0864\n",
      "Epochs  :13  Validation loss :4666.1772  Training loss :5759.665\n",
      "Epochs  :14  Validation loss :4660.0063  Training loss :5754.1943\n",
      "Epochs  :15  Validation loss :4653.913  Training loss :5748.8174\n",
      "Epochs  :16  Validation loss :4647.9893  Training loss :5743.5835\n",
      "Epochs  :17  Validation loss :4642.146  Training loss :5738.4517\n",
      "Epochs  :18  Validation loss :4636.406  Training loss :5733.4033\n",
      "Epochs  :19  Validation loss :4630.773  Training loss :5728.407\n",
      "Epochs  :20  Validation loss :4625.219  Training loss :5723.4683\n",
      "Epochs  :21  Validation loss :4619.734  Training loss :5718.627\n",
      "Epochs  :22  Validation loss :4614.413  Training loss :5714.017\n",
      "Epochs  :23  Validation loss :4609.0005  Training loss :5709.3003\n",
      "Epochs  :24  Validation loss :4603.8486  Training loss :5704.7476\n",
      "Epochs  :25  Validation loss :4599.098  Training loss :5701.159\n",
      "Epochs  :26  Validation loss :4593.3105  Training loss :5695.622\n",
      "Epochs  :27  Validation loss :4588.136  Training loss :5690.9673\n",
      "Epochs  :28  Validation loss :4583.014  Training loss :5686.4795\n",
      "Epochs  :29  Validation loss :4577.9243  Training loss :5682.099\n",
      "Epochs  :30  Validation loss :4572.8643  Training loss :5677.6777\n",
      "Epochs  :31  Validation loss :4567.8467  Training loss :5673.2705\n",
      "Epochs  :32  Validation loss :4562.887  Training loss :5668.9395\n",
      "Epochs  :33  Validation loss :4557.903  Training loss :5664.507\n",
      "Epochs  :34  Validation loss :4553.003  Training loss :5660.6387\n",
      "Epochs  :35  Validation loss :4548.1045  Training loss :5656.009\n",
      "Epochs  :36  Validation loss :4543.349  Training loss :5652.336\n",
      "Epochs  :37  Validation loss :4538.4355  Training loss :5647.6455\n",
      "Epochs  :38  Validation loss :4533.7656  Training loss :5644.044\n",
      "Epochs  :39  Validation loss :4529.11  Training loss :5639.6665\n",
      "Epochs  :40  Validation loss :4524.1045  Training loss :5635.79\n",
      "Epochs  :41  Validation loss :4521.7534  Training loss :5632.5073\n",
      "Epochs  :42  Validation loss :4514.8394  Training loss :5627.8286\n",
      "Epochs  :43  Validation loss :4510.1416  Training loss :5623.7085\n",
      "Epochs  :44  Validation loss :4505.557  Training loss :5619.615\n",
      "Epochs  :45  Validation loss :4500.722  Training loss :5615.8364\n",
      "Epochs  :46  Validation loss :4496.3286  Training loss :5611.6455\n",
      "Epochs  :47  Validation loss :4492.3296  Training loss :5608.0796\n",
      "Epochs  :48  Validation loss :4489.3086  Training loss :5605.908\n",
      "Epochs  :49  Validation loss :4482.394  Training loss :5600.3037\n",
      "Epochs  :50  Validation loss :4477.8125  Training loss :5596.0654\n",
      "Epochs  :51  Validation loss :4473.2334  Training loss :5592.264\n",
      "Epochs  :52  Validation loss :4468.702  Training loss :5588.4844\n",
      "Epochs  :53  Validation loss :4464.177  Training loss :5584.725\n",
      "Epochs  :54  Validation loss :4459.648  Training loss :5581.0215\n",
      "Epochs  :55  Validation loss :4455.179  Training loss :5577.3965\n",
      "Epochs  :56  Validation loss :4483.174  Training loss :5577.4043\n",
      "Epochs  :57  Validation loss :4447.044  Training loss :5575.193\n",
      "Epochs  :58  Validation loss :4442.216  Training loss :5566.688\n",
      "Epochs  :59  Validation loss :4437.805  Training loss :5562.966\n",
      "Epochs  :60  Validation loss :4433.412  Training loss :5559.3677\n",
      "Epochs  :61  Validation loss :4429.0356  Training loss :5555.7896\n",
      "Epochs  :62  Validation loss :4424.6753  Training loss :5552.226\n",
      "Epochs  :63  Validation loss :4420.333  Training loss :5548.6914\n",
      "Epochs  :64  Validation loss :4416.0083  Training loss :5545.1807\n",
      "Epochs  :65  Validation loss :4411.6987  Training loss :5541.6973\n",
      "Epochs  :66  Validation loss :4453.3506  Training loss :5540.5923\n",
      "Epochs  :67  Validation loss :4403.922  Training loss :5543.067\n",
      "Epochs  :68  Validation loss :4435.0464  Training loss :5557.5215\n",
      "Epochs  :69  Validation loss :4396.967  Training loss :5537.842\n",
      "Epochs  :70  Validation loss :4392.232  Training loss :5526.287\n",
      "Epochs  :71  Validation loss :4387.909  Training loss :5522.525\n",
      "Epochs  :72  Validation loss :4383.619  Training loss :5519.069\n",
      "Epochs  :73  Validation loss :4379.3853  Training loss :5515.6255\n",
      "Epochs  :74  Validation loss :4375.1895  Training loss :5512.238\n",
      "Epochs  :75  Validation loss :4371.0205  Training loss :5508.8804\n",
      "Epochs  :76  Validation loss :4366.8706  Training loss :5505.548\n",
      "Epochs  :77  Validation loss :4362.739  Training loss :5502.2334\n",
      "Epochs  :78  Validation loss :4358.624  Training loss :5498.944\n",
      "Epochs  :79  Validation loss :4354.5254  Training loss :5495.669\n",
      "Epochs  :80  Validation loss :4350.4414  Training loss :5492.415\n",
      "Epochs  :81  Validation loss :4346.3755  Training loss :5489.1777\n",
      "Epochs  :82  Validation loss :4342.3257  Training loss :5485.96\n",
      "Epochs  :83  Validation loss :4338.29  Training loss :5482.758\n",
      "Epochs  :84  Validation loss :4334.2705  Training loss :5479.5747\n",
      "Epochs  :85  Validation loss :4330.266  Training loss :5476.406\n",
      "Epochs  :86  Validation loss :4326.2803  Training loss :5473.2544\n",
      "Epochs  :87  Validation loss :4322.3174  Training loss :5470.118\n",
      "Epochs  :88  Validation loss :4318.372  Training loss :5466.996\n",
      "Epochs  :89  Validation loss :4314.42  Training loss :5463.8823\n",
      "Epochs  :90  Validation loss :4310.4844  Training loss :5460.782\n",
      "Epochs  :91  Validation loss :4306.544  Training loss :5457.7046\n",
      "Epochs  :92  Validation loss :4302.672  Training loss :5454.637\n",
      "Epochs  :93  Validation loss :4298.7974  Training loss :5451.6255\n",
      "Epochs  :94  Validation loss :4294.8823  Training loss :5448.579\n",
      "Epochs  :95  Validation loss :4290.975  Training loss :5445.5464\n",
      "Epochs  :96  Validation loss :4287.1  Training loss :5442.5425\n",
      "Epochs  :97  Validation loss :4283.217  Training loss :5439.5386\n",
      "Epochs  :98  Validation loss :4279.4717  Training loss :5436.649\n",
      "Epochs  :99  Validation loss :4275.883  Training loss :5436.9653\n",
      "Epochs  :100  Validation loss :4359.2104  Training loss :5491.0767\n",
      "Epochs  :101  Validation loss :4272.0713  Training loss :5454.672\n",
      "Epochs  :102  Validation loss :4271.317  Training loss :5448.077\n",
      "Epochs  :103  Validation loss :4263.6514  Training loss :5428.5435\n",
      "Epochs  :104  Validation loss :4259.6934  Training loss :5422.248\n",
      "Epochs  :105  Validation loss :4255.885  Training loss :5418.5156\n",
      "Epochs  :106  Validation loss :4252.124  Training loss :5415.5\n",
      "Epochs  :107  Validation loss :4248.3613  Training loss :5412.572\n",
      "Epochs  :108  Validation loss :4244.6367  Training loss :5409.671\n",
      "Epochs  :109  Validation loss :4240.8843  Training loss :5406.7637\n",
      "Epochs  :110  Validation loss :4237.153  Training loss :5403.8955\n",
      "Epochs  :111  Validation loss :4233.4287  Training loss :5401.0435\n",
      "Epochs  :112  Validation loss :4229.7246  Training loss :5398.213\n",
      "Epochs  :113  Validation loss :4226.0347  Training loss :5395.394\n",
      "Epochs  :114  Validation loss :4222.3584  Training loss :5392.594\n",
      "Epochs  :115  Validation loss :4218.6973  Training loss :5389.811\n",
      "Epochs  :116  Validation loss :4215.0537  Training loss :5387.044\n",
      "Epochs  :117  Validation loss :4211.4287  Training loss :5384.2876\n",
      "Epochs  :118  Validation loss :4207.8296  Training loss :5381.558\n",
      "Epochs  :119  Validation loss :4204.27  Training loss :5378.849\n",
      "Epochs  :120  Validation loss :4200.7036  Training loss :5376.217\n",
      "Epochs  :121  Validation loss :4201.212  Training loss :5379.018\n",
      "Epochs  :122  Validation loss :4201.119  Training loss :5434.5234\n",
      "Epochs  :123  Validation loss :4370.7466  Training loss :5584.867\n",
      "Epochs  :124  Validation loss :4206.009  Training loss :5425.845\n",
      "Epochs  :125  Validation loss :4195.4  Training loss :5380.9194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs  :126  Validation loss :4192.8633  Training loss :5374.394\n",
      "Epochs  :127  Validation loss :4188.895  Training loss :5371.25\n",
      "Epochs  :128  Validation loss :4185.1436  Training loss :5367.03\n",
      "Epochs  :129  Validation loss :4181.445  Training loss :5363.599\n",
      "Epochs  :130  Validation loss :4177.5454  Training loss :5360.4116\n",
      "Epochs  :131  Validation loss :4171.975  Training loss :5356.931\n",
      "Epochs  :132  Validation loss :4167.388  Training loss :5352.5884\n",
      "Epochs  :133  Validation loss :4163.311  Training loss :5349.0317\n",
      "Epochs  :134  Validation loss :4159.7627  Training loss :5346.2075\n",
      "Epochs  :135  Validation loss :4156.2935  Training loss :5343.401\n",
      "Epochs  :136  Validation loss :4152.8047  Training loss :5340.6846\n",
      "Epochs  :137  Validation loss :4149.2905  Training loss :5338.012\n",
      "Epochs  :138  Validation loss :4145.753  Training loss :5335.359\n",
      "Epochs  :139  Validation loss :4142.181  Training loss :5332.717\n",
      "Epochs  :140  Validation loss :4138.5938  Training loss :5330.092\n",
      "Epochs  :141  Validation loss :4135.0303  Training loss :5327.4907\n",
      "Epochs  :142  Validation loss :4131.52  Training loss :5324.919\n",
      "Epochs  :143  Validation loss :4128.06  Training loss :5322.372\n",
      "Epochs  :144  Validation loss :4124.6377  Training loss :5319.8477\n",
      "Epochs  :145  Validation loss :4121.243  Training loss :5317.3364\n",
      "Epochs  :146  Validation loss :4117.868  Training loss :5314.8364\n",
      "Epochs  :147  Validation loss :4114.5054  Training loss :5312.351\n",
      "Epochs  :148  Validation loss :4111.148  Training loss :5309.8765\n",
      "Epochs  :149  Validation loss :4107.7954  Training loss :5307.416\n",
      "Epochs  :150  Validation loss :4104.457  Training loss :5304.969\n",
      "Epochs  :151  Validation loss :4101.1416  Training loss :5302.54\n",
      "Epochs  :152  Validation loss :4097.885  Training loss :5300.1616\n",
      "Epochs  :153  Validation loss :4095.1968  Training loss :5298.4517\n",
      "Epochs  :154  Validation loss :4091.9707  Training loss :5305.548\n",
      "Epochs  :155  Validation loss :4088.1553  Training loss :5293.8535\n",
      "Epochs  :156  Validation loss :4087.1409  Training loss :5294.155\n",
      "Epochs  :157  Validation loss :4081.8062  Training loss :5288.807\n",
      "Epochs  :158  Validation loss :4080.4053  Training loss :5286.476\n",
      "Epochs  :159  Validation loss :4075.2102  Training loss :5283.8105\n",
      "Epochs  :160  Validation loss :4074.8108  Training loss :5286.838\n",
      "Epochs  :161  Validation loss :4071.4167  Training loss :5368.0815\n",
      "Epochs  :162  Validation loss :4067.4019  Training loss :5279.7637\n",
      "Epochs  :163  Validation loss :4064.0466  Training loss :5276.9653\n",
      "Epochs  :164  Validation loss :4060.8179  Training loss :5274.488\n",
      "Epochs  :165  Validation loss :4057.5698  Training loss :5271.623\n",
      "Epochs  :166  Validation loss :4054.361  Training loss :5269.2593\n",
      "Epochs  :167  Validation loss :4051.2026  Training loss :5266.9023\n",
      "Epochs  :168  Validation loss :4048.1414  Training loss :5264.618\n",
      "Epochs  :169  Validation loss :4044.8247  Training loss :5262.2104\n",
      "Epochs  :170  Validation loss :4041.6748  Training loss :5259.986\n",
      "Epochs  :171  Validation loss :4038.4773  Training loss :5257.2207\n",
      "Epochs  :172  Validation loss :4035.3132  Training loss :5254.877\n",
      "Epochs  :173  Validation loss :4032.1797  Training loss :5252.593\n",
      "Epochs  :174  Validation loss :4029.0293  Training loss :5250.395\n",
      "Epochs  :175  Validation loss :4025.9077  Training loss :5248.127\n",
      "Epochs  :176  Validation loss :4022.9053  Training loss :5246.129\n",
      "Epochs  :177  Validation loss :4019.6614  Training loss :5243.7246\n",
      "Epochs  :178  Validation loss :4016.5637  Training loss :5241.4536\n",
      "Epochs  :179  Validation loss :4014.3308  Training loss :5239.5537\n",
      "Epochs  :180  Validation loss :4010.3884  Training loss :5237.378\n",
      "Epochs  :181  Validation loss :4007.2827  Training loss :5234.849\n",
      "Epochs  :182  Validation loss :4004.2046  Training loss :5232.6567\n",
      "Epochs  :183  Validation loss :4001.1443  Training loss :5230.505\n",
      "Epochs  :184  Validation loss :3998.0713  Training loss :5228.3364\n",
      "Epochs  :185  Validation loss :3995.038  Training loss :5226.1836\n",
      "Epochs  :186  Validation loss :3991.9688  Training loss :5224.04\n",
      "Epochs  :187  Validation loss :3990.298  Training loss :5222.013\n",
      "Epochs  :188  Validation loss :3986.125  Training loss :5219.9624\n",
      "Epochs  :189  Validation loss :3983.2551  Training loss :5218.365\n",
      "Epochs  :190  Validation loss :3979.9055  Training loss :5215.883\n",
      "Epochs  :191  Validation loss :4132.33  Training loss :5253.8286\n",
      "Epochs  :192  Validation loss :3975.8296  Training loss :5256.255\n",
      "Epochs  :193  Validation loss :4040.277  Training loss :5330.4453\n",
      "Epochs  :194  Validation loss :4245.863  Training loss :5535.4546\n",
      "Epochs  :195  Validation loss :4028.5112  Training loss :5310.5586\n",
      "Epochs  :196  Validation loss :4001.65  Training loss :5237.9175\n",
      "Epochs  :197  Validation loss :3988.5486  Training loss :5225.5015\n",
      "Epochs  :198  Validation loss :3979.9656  Training loss :5218.993\n",
      "Epochs  :199  Validation loss :3974.196  Training loss :5213.4844\n",
      "Epochs  :200  Validation loss :3969.131  Training loss :5209.7017\n",
      "Epochs  :201  Validation loss :3964.074  Training loss :5206.421\n",
      "Epochs  :202  Validation loss :3959.5566  Training loss :5203.4697\n",
      "Epochs  :203  Validation loss :3955.47  Training loss :5200.7393\n",
      "Epochs  :204  Validation loss :3951.6738  Training loss :5198.1523\n",
      "Epochs  :205  Validation loss :3948.0903  Training loss :5195.672\n",
      "Epochs  :206  Validation loss :3944.6375  Training loss :5193.282\n",
      "Epochs  :207  Validation loss :3941.2595  Training loss :5190.9717\n",
      "Epochs  :208  Validation loss :3937.954  Training loss :5188.73\n",
      "Epochs  :209  Validation loss :3934.6892  Training loss :5186.558\n",
      "Epochs  :210  Validation loss :3931.491  Training loss :5184.4443\n",
      "Epochs  :211  Validation loss :3928.4353  Training loss :5182.3486\n",
      "Epochs  :212  Validation loss :3925.4614  Training loss :5180.3037\n",
      "Epochs  :213  Validation loss :3922.4558  Training loss :5178.3467\n",
      "Epochs  :214  Validation loss :3919.4302  Training loss :5176.4536\n",
      "Epochs  :215  Validation loss :3916.458  Training loss :5174.595\n",
      "Epochs  :216  Validation loss :3913.5806  Training loss :5172.823\n",
      "Epochs  :217  Validation loss :3910.778  Training loss :5171.3696\n",
      "Epochs  :218  Validation loss :3907.7534  Training loss :5170.4556\n",
      "Epochs  :219  Validation loss :3904.7864  Training loss :5166.943\n",
      "Epochs  :220  Validation loss :3901.9177  Training loss :5165.294\n",
      "Epochs  :221  Validation loss :3899.0784  Training loss :5163.686\n",
      "Epochs  :222  Validation loss :3896.5898  Training loss :5162.583\n",
      "Epochs  :223  Validation loss :3894.2444  Training loss :5161.5723\n",
      "Epochs  :224  Validation loss :3890.9236  Training loss :5157.921\n",
      "Epochs  :225  Validation loss :3888.3447  Training loss :5156.759\n",
      "Epochs  :226  Validation loss :3886.328  Training loss :5186.821\n",
      "Epochs  :227  Validation loss :3884.1184  Training loss :5154.4766\n",
      "Epochs  :228  Validation loss :3880.3333  Training loss :5148.294\n",
      "Epochs  :229  Validation loss :3877.8281  Training loss :5146.6465\n",
      "Epochs  :230  Validation loss :3874.8477  Training loss :5144.4277\n",
      "Epochs  :231  Validation loss :3872.9443  Training loss :5143.645\n",
      "Epochs  :232  Validation loss :3869.086  Training loss :5140.673\n",
      "Epochs  :233  Validation loss :3866.723  Training loss :5145.7397\n",
      "Epochs  :234  Validation loss :3865.2742  Training loss :5194.8145\n",
      "Epochs  :235  Validation loss :3863.3303  Training loss :5139.3906\n",
      "Epochs  :236  Validation loss :3858.8723  Training loss :5134.6865\n",
      "Epochs  :237  Validation loss :3857.1274  Training loss :5133.0845\n",
      "Epochs  :238  Validation loss :3853.348  Training loss :5129.9736\n",
      "Epochs  :239  Validation loss :3851.219  Training loss :5131.197\n",
      "Epochs  :240  Validation loss :3848.8464  Training loss :5163.642\n",
      "Epochs  :241  Validation loss :3847.2617  Training loss :5126.1045\n",
      "Epochs  :242  Validation loss :3843.9746  Training loss :5123.5005\n",
      "Epochs  :243  Validation loss :3840.8064  Training loss :5121.12\n",
      "Epochs  :244  Validation loss :3838.0217  Training loss :5120.589\n",
      "Epochs  :245  Validation loss :3837.7844  Training loss :5156.561\n",
      "Epochs  :246  Validation loss :3834.966  Training loss :5155.337\n",
      "Epochs  :247  Validation loss :3833.5657  Training loss :5116.568\n",
      "Epochs  :248  Validation loss :3828.5215  Training loss :5113.7183\n",
      "Epochs  :249  Validation loss :3825.9014  Training loss :5110.307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs  :250  Validation loss :3823.2603  Training loss :5108.9565\n",
      "Epochs  :251  Validation loss :3820.6135  Training loss :5106.755\n",
      "Epochs  :252  Validation loss :3817.89  Training loss :5104.877\n",
      "Epochs  :253  Validation loss :3815.1624  Training loss :5103.0815\n",
      "Epochs  :254  Validation loss :3812.4048  Training loss :5101.7056\n",
      "Epochs  :255  Validation loss :3810.3855  Training loss :5104.1895\n",
      "Epochs  :256  Validation loss :3807.3877  Training loss :5097.899\n",
      "Epochs  :257  Validation loss :3806.5342  Training loss :5124.166\n",
      "Epochs  :258  Validation loss :3802.5925  Training loss :5101.055\n",
      "Epochs  :259  Validation loss :3801.9153  Training loss :5096.314\n",
      "Epochs  :260  Validation loss :3798.0688  Training loss :5095.707\n",
      "Epochs  :261  Validation loss :3797.846  Training loss :5163.257\n",
      "Epochs  :262  Validation loss :3794.3967  Training loss :5092.2793\n",
      "Epochs  :263  Validation loss :3791.7202  Training loss :5088.9243\n",
      "Epochs  :264  Validation loss :3788.612  Training loss :5085.1514\n",
      "Epochs  :265  Validation loss :3785.8381  Training loss :5082.9673\n",
      "Epochs  :266  Validation loss :3783.2095  Training loss :5081.093\n",
      "Epochs  :267  Validation loss :3780.5857  Training loss :5079.365\n",
      "Epochs  :268  Validation loss :3777.9905  Training loss :5077.6777\n",
      "Epochs  :269  Validation loss :3775.425  Training loss :5076.04\n",
      "Epochs  :270  Validation loss :3772.8171  Training loss :5074.427\n",
      "Epochs  :271  Validation loss :3770.6077  Training loss :5073.182\n",
      "Epochs  :272  Validation loss :3767.5583  Training loss :5071.278\n",
      "Epochs  :273  Validation loss :3766.2048  Training loss :5075.334\n",
      "Epochs  :274  Validation loss :3762.9185  Training loss :5072.4077\n",
      "Epochs  :275  Validation loss :3762.6946  Training loss :5160.358\n",
      "Epochs  :276  Validation loss :3758.9702  Training loss :5071.9785\n",
      "Epochs  :277  Validation loss :3756.3643  Training loss :5064.1934\n",
      "Epochs  :278  Validation loss :3753.4756  Training loss :5062.2393\n",
      "Epochs  :279  Validation loss :3751.3635  Training loss :5059.8975\n",
      "Epochs  :280  Validation loss :3748.5588  Training loss :5058.1016\n",
      "Epochs  :281  Validation loss :3746.023  Training loss :5056.4717\n",
      "Epochs  :282  Validation loss :3743.447  Training loss :5054.7583\n",
      "Epochs  :283  Validation loss :3740.9148  Training loss :5053.125\n",
      "Epochs  :284  Validation loss :3738.4023  Training loss :5051.511\n",
      "Epochs  :285  Validation loss :3735.909  Training loss :5049.893\n",
      "Epochs  :286  Validation loss :3733.4114  Training loss :5048.256\n",
      "Epochs  :287  Validation loss :3730.9553  Training loss :5046.6187\n",
      "Epochs  :288  Validation loss :3729.127  Training loss :5044.972\n",
      "Epochs  :289  Validation loss :3726.7952  Training loss :5043.479\n",
      "Epochs  :290  Validation loss :3724.821  Training loss :5042.4116\n",
      "Epochs  :291  Validation loss :3725.592  Training loss :5043.231\n",
      "Epochs  :292  Validation loss :3720.1238  Training loss :5053.327\n",
      "Epochs  :293  Validation loss :3733.244  Training loss :5131.513\n",
      "Epochs  :294  Validation loss :3735.1206  Training loss :5095.453\n",
      "Epochs  :295  Validation loss :3715.2065  Training loss :5069.9287\n",
      "Epochs  :296  Validation loss :3712.172  Training loss :5045.026\n",
      "Epochs  :297  Validation loss :3709.8503  Training loss :5039.06\n",
      "Epochs  :298  Validation loss :3707.1353  Training loss :5036.497\n",
      "Epochs  :299  Validation loss :3705.435  Training loss :5033.07\n",
      "Epochs  :300  Validation loss :3702.8757  Training loss :5029.837\n",
      "Epochs  :301  Validation loss :3700.7405  Training loss :5027.86\n",
      "Epochs  :302  Validation loss :3698.0376  Training loss :5025.2983\n",
      "Epochs  :303  Validation loss :3695.618  Training loss :5022.9136\n",
      "Epochs  :304  Validation loss :3692.7175  Training loss :5021.386\n",
      "Epochs  :305  Validation loss :3690.8523  Training loss :5022.3506\n",
      "Epochs  :306  Validation loss :3709.928  Training loss :5130.217\n",
      "Epochs  :307  Validation loss :3687.238  Training loss :5034.369\n",
      "Epochs  :308  Validation loss :3684.811  Training loss :5024.6357\n",
      "Epochs  :309  Validation loss :3682.4478  Training loss :5018.8223\n",
      "Epochs  :310  Validation loss :3679.81  Training loss :5014.8335\n",
      "Epochs  :311  Validation loss :3676.703  Training loss :5011.921\n",
      "Epochs  :312  Validation loss :3674.3982  Training loss :5009.872\n",
      "Epochs  :313  Validation loss :3672.4336  Training loss :5007.8213\n",
      "Epochs  :314  Validation loss :3670.1184  Training loss :5006.263\n",
      "Epochs  :315  Validation loss :3668.561  Training loss :5004.629\n",
      "Epochs  :316  Validation loss :3666.2825  Training loss :5003.2607\n",
      "Epochs  :317  Validation loss :3662.182  Training loss :5002.9756\n",
      "Epochs  :318  Validation loss :3661.3872  Training loss :5000.759\n",
      "Epochs  :319  Validation loss :3659.486  Training loss :4999.198\n",
      "Epochs  :320  Validation loss :3656.9968  Training loss :4997.264\n",
      "Epochs  :321  Validation loss :3655.0027  Training loss :4996.2217\n",
      "Epochs  :322  Validation loss :3652.7642  Training loss :4995.2114\n",
      "Epochs  :323  Validation loss :3650.3787  Training loss :4993.785\n",
      "Epochs  :324  Validation loss :3648.3403  Training loss :4995.9526\n",
      "Epochs  :325  Validation loss :3645.6592  Training loss :4994.59\n",
      "Epochs  :326  Validation loss :3641.518  Training loss :4991.525\n",
      "Epochs  :327  Validation loss :3641.2837  Training loss :4987.8105\n",
      "Epochs  :328  Validation loss :3639.022  Training loss :4986.7344\n",
      "Epochs  :329  Validation loss :3927.4236  Training loss :5154.717\n",
      "Epochs  :330  Validation loss :3641.0676  Training loss :5054.926\n",
      "Epochs  :331  Validation loss :3636.7185  Training loss :5000.1104\n",
      "Epochs  :332  Validation loss :3634.0007  Training loss :4989.818\n",
      "Epochs  :333  Validation loss :3632.446  Training loss :5031.95\n",
      "Epochs  :334  Validation loss :3629.4216  Training loss :4988.688\n",
      "Epochs  :335  Validation loss :3625.8372  Training loss :4989.0444\n",
      "Epochs  :336  Validation loss :3622.4246  Training loss :4984.4263\n",
      "Epochs  :337  Validation loss :3619.3796  Training loss :4982.0957\n",
      "Epochs  :338  Validation loss :3617.2744  Training loss :4976.362\n",
      "Epochs  :339  Validation loss :3621.5784  Training loss :4978.3315\n",
      "Epochs  :340  Validation loss :3613.0288  Training loss :4971.462\n",
      "Epochs  :341  Validation loss :3610.0332  Training loss :4969.8823\n",
      "Epochs  :342  Validation loss :3611.1523  Training loss :4966.7075\n",
      "Epochs  :343  Validation loss :3606.9353  Training loss :4968.187\n",
      "Epochs  :344  Validation loss :3608.471  Training loss :5000.517\n",
      "Epochs  :345  Validation loss :3606.5366  Training loss :4979.0293\n",
      "Epochs  :346  Validation loss :3601.0593  Training loss :4968.371\n",
      "Epochs  :347  Validation loss :3601.7505  Training loss :4973.2393\n",
      "Epochs  :348  Validation loss :3596.1782  Training loss :4968.611\n",
      "Epochs  :349  Validation loss :3593.6292  Training loss :4965.161\n",
      "Epochs  :350  Validation loss :3593.1663  Training loss :4956.2944\n",
      "Epochs  :351  Validation loss :3591.8003  Training loss :4954.797\n",
      "Epochs  :352  Validation loss :3585.576  Training loss :4954.612\n",
      "Epochs  :353  Validation loss :3588.26  Training loss :4952.47\n",
      "Epochs  :354  Validation loss :3581.3503  Training loss :4961.717\n",
      "Epochs  :355  Validation loss :3579.0708  Training loss :4949.4087\n",
      "Epochs  :356  Validation loss :3578.2456  Training loss :4946.9067\n",
      "Epochs  :357  Validation loss :3574.9375  Training loss :4945.85\n",
      "Epochs  :358  Validation loss :3573.1528  Training loss :4946.4463\n",
      "Epochs  :359  Validation loss :3570.0818  Training loss :4942.9814\n",
      "Epochs  :360  Validation loss :3572.6975  Training loss :4941.9277\n",
      "Epochs  :361  Validation loss :3572.5024  Training loss :4956.986\n",
      "Epochs  :362  Validation loss :3569.7678  Training loss :4953.048\n",
      "Epochs  :363  Validation loss :3566.8618  Training loss :4944.9683\n",
      "Epochs  :364  Validation loss :3560.6174  Training loss :4936.8906\n",
      "Epochs  :365  Validation loss :3559.9792  Training loss :4936.5938\n",
      "Epochs  :366  Validation loss :3592.8884  Training loss :5009.3677\n",
      "Epochs  :367  Validation loss :3560.5322  Training loss :4963.899\n",
      "Epochs  :368  Validation loss :3552.412  Training loss :4941.292\n",
      "Epochs  :369  Validation loss :3550.1301  Training loss :4932.035\n",
      "Epochs  :370  Validation loss :3547.2568  Training loss :4929.844\n",
      "Epochs  :371  Validation loss :3546.6487  Training loss :4927.9204\n",
      "Epochs  :372  Validation loss :3544.539  Training loss :4927.5327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs  :373  Validation loss :3546.0178  Training loss :4926.7725\n",
      "Epochs  :374  Validation loss :3538.585  Training loss :4929.119\n",
      "Epochs  :375  Validation loss :3541.8599  Training loss :4934.895\n",
      "Epochs  :376  Validation loss :3539.3582  Training loss :4924.5435\n",
      "Epochs  :377  Validation loss :3540.2036  Training loss :4933.564\n",
      "Epochs  :378  Validation loss :3536.2192  Training loss :4922.634\n",
      "Epochs  :379  Validation loss :3536.0928  Training loss :4970.248\n",
      "Epochs  :380  Validation loss :3540.2886  Training loss :4982.2656\n",
      "Epochs  :381  Validation loss :3550.572  Training loss :4931.03\n",
      "Epochs  :382  Validation loss :3523.1125  Training loss :4916.4185\n",
      "Epochs  :383  Validation loss :3520.805  Training loss :4912.711\n",
      "Epochs  :384  Validation loss :3518.7773  Training loss :4910.421\n",
      "Epochs  :385  Validation loss :3516.428  Training loss :4909.7607\n",
      "Epochs  :386  Validation loss :3514.3193  Training loss :4907.0283\n",
      "Epochs  :387  Validation loss :3512.2173  Training loss :4906.29\n",
      "Epochs  :388  Validation loss :3510.714  Training loss :4904.8438\n",
      "Epochs  :389  Validation loss :3510.3882  Training loss :4904.4985\n",
      "Epochs  :390  Validation loss :3507.5369  Training loss :4903.4478\n",
      "Epochs  :391  Validation loss :3507.3838  Training loss :4904.237\n",
      "Epochs  :392  Validation loss :3503.4158  Training loss :4961.873\n",
      "Epochs  :393  Validation loss :3500.4502  Training loss :4917.307\n",
      "Epochs  :394  Validation loss :3499.465  Training loss :4916.41\n",
      "Epochs  :395  Validation loss :3496.6328  Training loss :4908.3677\n",
      "Epochs  :396  Validation loss :3494.9006  Training loss :4901.995\n",
      "Epochs  :397  Validation loss :3499.8555  Training loss :4898.1797\n",
      "Epochs  :398  Validation loss :3498.972  Training loss :4952.9033\n",
      "Epochs  :399  Validation loss :3488.7192  Training loss :4912.315\n",
      "Epochs  :400  Validation loss :3494.253  Training loss :4894.7783\n",
      "Epochs  :401  Validation loss :3492.3655  Training loss :4909.6934\n",
      "Epochs  :402  Validation loss :3483.096  Training loss :4890.9185\n",
      "Epochs  :403  Validation loss :3480.7542  Training loss :4894.3726\n",
      "Epochs  :404  Validation loss :3478.521  Training loss :4886.551\n",
      "Epochs  :405  Validation loss :3476.3745  Training loss :4884.2876\n",
      "Epochs  :406  Validation loss :3474.4412  Training loss :4884.6655\n",
      "Epochs  :407  Validation loss :3472.7947  Training loss :4886.2705\n",
      "Epochs  :408  Validation loss :3472.2751  Training loss :4880.88\n",
      "Epochs  :409  Validation loss :3468.3264  Training loss :4880.0483\n",
      "Epochs  :410  Validation loss :3466.0425  Training loss :4878.189\n",
      "Epochs  :411  Validation loss :3463.9053  Training loss :4877.0767\n",
      "Epochs  :412  Validation loss :3461.8618  Training loss :4876.246\n",
      "Epochs  :413  Validation loss :3459.7847  Training loss :4874.7373\n",
      "Epochs  :414  Validation loss :3459.243  Training loss :4880.4644\n",
      "Epochs  :415  Validation loss :3524.8389  Training loss :4940.1523\n",
      "Epochs  :416  Validation loss :3472.5796  Training loss :4936.9487\n",
      "Epochs  :417  Validation loss :3466.1594  Training loss :4909.2456\n",
      "Epochs  :418  Validation loss :3452.0764  Training loss :4909.3374\n",
      "Epochs  :419  Validation loss :3453.6794  Training loss :4879.034\n",
      "Epochs  :420  Validation loss :3449.5388  Training loss :4877.6074\n",
      "Epochs  :421  Validation loss :3446.5803  Training loss :4875.374\n",
      "Epochs  :422  Validation loss :3443.3777  Training loss :4866.6724\n",
      "Epochs  :423  Validation loss :3441.335  Training loss :4866.262\n",
      "Epochs  :424  Validation loss :3439.2104  Training loss :4863.193\n",
      "Epochs  :425  Validation loss :3437.167  Training loss :4859.827\n",
      "Epochs  :426  Validation loss :3435.1035  Training loss :4859.5693\n",
      "Epochs  :427  Validation loss :3433.0225  Training loss :4856.999\n",
      "Epochs  :428  Validation loss :3430.994  Training loss :4855.3784\n",
      "Epochs  :429  Validation loss :3429.0237  Training loss :4855.6235\n",
      "Epochs  :430  Validation loss :3426.9363  Training loss :4854.62\n",
      "Epochs  :431  Validation loss :3424.9211  Training loss :4851.9404\n",
      "Epochs  :432  Validation loss :3423.5698  Training loss :4852.032\n",
      "Epochs  :433  Validation loss :3422.2542  Training loss :4852.5317\n",
      "Epochs  :434  Validation loss :3419.205  Training loss :4850.5576\n",
      "Epochs  :435  Validation loss :3417.0925  Training loss :4848.4546\n",
      "Epochs  :436  Validation loss :3415.0415  Training loss :4846.193\n",
      "Epochs  :437  Validation loss :3416.9133  Training loss :4852.018\n",
      "Epochs  :438  Validation loss :3411.599  Training loss :4846.52\n",
      "Epochs  :439  Validation loss :3409.0308  Training loss :4842.643\n",
      "Epochs  :440  Validation loss :3407.2078  Training loss :4840.399\n",
      "Epochs  :441  Validation loss :3404.9756  Training loss :4839.842\n",
      "Epochs  :442  Validation loss :3403.4182  Training loss :4837.754\n",
      "Epochs  :443  Validation loss :3404.3445  Training loss :4859.865\n",
      "Epochs  :444  Validation loss :3399.238  Training loss :4839.4937\n",
      "Epochs  :445  Validation loss :4053.2258  Training loss :4909.519\n",
      "Epochs  :446  Validation loss :3403.8345  Training loss :4909.5806\n",
      "Epochs  :447  Validation loss :3394.75  Training loss :4837.311\n",
      "Epochs  :448  Validation loss :3406.2224  Training loss :4835.0537\n",
      "Epochs  :449  Validation loss :3396.0999  Training loss :4841.3096\n",
      "Epochs  :450  Validation loss :3389.798  Training loss :4844.085\n",
      "Epochs  :451  Validation loss :3386.6343  Training loss :4831.7964\n",
      "Epochs  :452  Validation loss :3386.0728  Training loss :4831.446\n",
      "Epochs  :453  Validation loss :3383.0232  Training loss :4827.5415\n",
      "Epochs  :454  Validation loss :3380.6152  Training loss :4827.939\n",
      "Epochs  :455  Validation loss :3378.4243  Training loss :4824.0317\n",
      "Epochs  :456  Validation loss :3376.7046  Training loss :4822.589\n",
      "Epochs  :457  Validation loss :3374.4614  Training loss :4821.5815\n",
      "Epochs  :458  Validation loss :3372.5044  Training loss :4820.0737\n",
      "Epochs  :459  Validation loss :3370.5137  Training loss :4818.677\n",
      "Epochs  :460  Validation loss :3369.0854  Training loss :4817.608\n",
      "Epochs  :461  Validation loss :3366.6023  Training loss :4817.1826\n",
      "Epochs  :462  Validation loss :3364.6726  Training loss :4816.5757\n",
      "Epochs  :463  Validation loss :3362.9543  Training loss :4818.276\n",
      "Epochs  :464  Validation loss :3363.006  Training loss :4826.433\n",
      "Epochs  :465  Validation loss :3362.1787  Training loss :4835.094\n",
      "Epochs  :466  Validation loss :3373.5808  Training loss :4878.1987\n",
      "Epochs  :467  Validation loss :3359.3162  Training loss :4833.461\n",
      "Epochs  :468  Validation loss :3354.6614  Training loss :4809.334\n",
      "Epochs  :469  Validation loss :3352.3503  Training loss :4807.664\n",
      "Epochs  :470  Validation loss :3350.166  Training loss :4805.776\n",
      "Epochs  :471  Validation loss :3352.301  Training loss :4808.505\n",
      "Epochs  :472  Validation loss :3346.585  Training loss :4803.7812\n",
      "Epochs  :473  Validation loss :3344.239  Training loss :4801.8945\n",
      "Epochs  :474  Validation loss :3342.443  Training loss :4805.238\n",
      "Epochs  :475  Validation loss :3340.4575  Training loss :4802.27\n",
      "Epochs  :476  Validation loss :3338.6755  Training loss :4800.65\n",
      "Epochs  :477  Validation loss :3353.5637  Training loss :4813.726\n",
      "Epochs  :478  Validation loss :3347.5657  Training loss :4858.161\n",
      "Epochs  :479  Validation loss :3333.6301  Training loss :4805.259\n",
      "Epochs  :480  Validation loss :3331.672  Training loss :4794.959\n",
      "Epochs  :481  Validation loss :3329.5386  Training loss :4792.4883\n",
      "Epochs  :482  Validation loss :3327.571  Training loss :4791.0967\n",
      "Epochs  :483  Validation loss :3325.611  Training loss :4789.8003\n",
      "Epochs  :484  Validation loss :3323.6687  Training loss :4788.522\n",
      "Epochs  :485  Validation loss :3321.7258  Training loss :4787.32\n",
      "Epochs  :486  Validation loss :3319.8389  Training loss :4786.1597\n",
      "Epochs  :487  Validation loss :3317.9463  Training loss :4784.953\n",
      "Epochs  :488  Validation loss :3315.9348  Training loss :4783.729\n",
      "Epochs  :489  Validation loss :3315.8506  Training loss :4785.9995\n",
      "Epochs  :490  Validation loss :3315.4534  Training loss :4787.2954\n",
      "Epochs  :491  Validation loss :3310.7747  Training loss :4784.763\n",
      "Epochs  :492  Validation loss :3308.3838  Training loss :4781.942\n",
      "Epochs  :493  Validation loss :3306.437  Training loss :4779.136\n",
      "Epochs  :494  Validation loss :3304.7373  Training loss :4777.6924\n",
      "Epochs  :495  Validation loss :3303.8345  Training loss :4783.8965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs  :496  Validation loss :3407.1082  Training loss :4936.204\n",
      "Epochs  :497  Validation loss :3920.4705  Training loss :4837.757\n",
      "Epochs  :498  Validation loss :3328.792  Training loss :4821.824\n",
      "Epochs  :499  Validation loss :3300.0203  Training loss :4804.5513\n",
      "Epochs  :500  Validation loss :3296.1982  Training loss :4798.933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Chain(Dense(4, 128), Dense(128, 64, tanh), Dense(64, 32, tanh), Dense(32, 32, tanh), Dense(32, 1)), 3296.1982f0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train=rand(4,10000)|>gpu\n",
    "y_train= Array(( x_train[1,:]' ./ x_train[3,:]') .- log.(x_train[2,:]'.+x_train[4,:]))|>gpu\n",
    "x_val=rand(4,1000)|>gpu\n",
    "y_val= Array(( x_val[1,:]' ./ x_val[3,:]' ).- log.(x_val[2,:]'.+x_val[4,:]) )|>gpu\n",
    "model, val_loss = train_model(x_train, y_train,x_val,y_val,500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Property of a Neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combinations :[1]  Error :4.859957e7  Median Error 0.46481317\n",
      "Combinations :[2]  Error :4.8301908e7  Median Error 0.36272502\n",
      "Combinations :[3]  Error :4.862897e7  Median Error 0.4609959\n",
      "Combinations :[4]  Error :4.8296436e7  Median Error 0.37861085\n",
      "Combinations :[1, 2]  Error :4.8636764e7  Median Error 0.46059644\n",
      "Combinations :[1, 3]  Error :4.8346668e7  Median Error 0.36789596\n",
      "Combinations :[1, 4]  Error :4.857916e7  Median Error 0.46528995\n",
      "Combinations :[2, 3]  Error :4.857916e7  Median Error 0.46528995\n",
      "Combinations :[2, 4]  Error :4.8346668e7  Median Error 0.36789596\n",
      "Combinations :[3, 4]  Error :4.8636764e7  Median Error 0.46059644\n",
      "Combinations :[1, 2, 3]  Error :4.8296436e7  Median Error 0.37861085\n",
      "Combinations :[1, 2, 4]  Error :4.862897e7  Median Error 0.4609959\n",
      "Combinations :[1, 3, 4]  Error :4.8301908e7  Median Error 0.36272502\n",
      "Combinations :[2, 3, 4]  Error :4.859957e7  Median Error 0.46481317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(nothing, nothing, 1000000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_additive(model, x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check property with a different C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combinations :[1]  Error :6.0294664e7  Median Error 11.917676\n",
      "Combinations :[2]  Error :5.5366976e7  Median Error 0.6556463\n",
      "Combinations :[3]  Error :7.033074e7  Median Error 9.08481\n",
      "Combinations :[4]  Error :5.6700212e7  Median Error 0.66992736\n",
      "Combinations :[1, 2]  Error :6.802867e7  Median Error 16.229298\n",
      "Combinations :[1, 3]  Error :1.1970588e8  Median Error 2.2768598\n",
      "Combinations :[1, 4]  Error :6.0250264e7  Median Error 9.0442915\n",
      "Combinations :[2, 3]  Error :6.0250264e7  Median Error 9.0442915\n",
      "Combinations :[2, 4]  Error :1.1970588e8  Median Error 2.2768598\n",
      "Combinations :[3, 4]  Error :6.802867e7  Median Error 16.229298\n",
      "Combinations :[1, 2, 3]  Error :5.6700212e7  Median Error 0.66992736\n",
      "Combinations :[1, 2, 4]  Error :7.033074e7  Median Error 9.08481\n",
      "Combinations :[1, 3, 4]  Error :5.5366976e7  Median Error 0.6556463\n",
      "Combinations :[2, 3, 4]  Error :6.0294664e7  Median Error 11.917676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(nothing, nothing, 100000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_multiplicative(model, x_train,y_train, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check translation Symmetry "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 1 j :2 Error :4834.498\n",
      "  Median Error 0.37217978\n",
      "i: 1 j :3 Error :4834.4766\n",
      "  Median Error 0.37220466\n",
      "i: 1 j :4 Error :4834.449\n",
      "  Median Error 0.37219334\n",
      "i: 2 j :3 Error :4834.5806\n",
      "  Median Error 0.3722086\n",
      "i: 2 j :4 Error :4834.553\n",
      "  Median Error 0.3721975\n",
      "i: 3 j :4 Error :4834.5317\n",
      "  Median Error 0.3722222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1000, -1, -1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_translational_symmetry_plus(model, x_train,y_train,val_loss )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
